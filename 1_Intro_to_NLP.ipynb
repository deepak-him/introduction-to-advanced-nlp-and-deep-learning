{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMquYNi_VsTR"
      },
      "source": [
        "## **What is NLP (Natural Language Processing)?**\n",
        "\n",
        "NLP is a branch of data science that consists of systematic processes for analyzing, understanding, and deriving information from the text data in a smart and efficient manner. By utilizing NLP and its components, one can organize the massive chunks of text data, perform numerous automated tasks and solve a wide range of problems such as – automatic summarization, machine translation, named entity recognition, relationship extraction, sentiment analysis, speech recognition, topic segmentation etc.\n",
        "\n",
        "Nowadays, most of us have smartphones that have speech recognition. These smartphones use NLP to understand what is said. Also, many people use laptops whose operating system has a built-in speech recognition.\n",
        "\n",
        "Example:\n",
        "**Cortana**\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/1*TXj0kr4jVrtLtmvxZFu8Lw.png\" height=\"200\" width=\"500\">\n",
        "\n",
        "The Microsoft OS has a virtual assistant called Cortana that can recognize a natural voice. You can use it to set up reminders, open apps, send emails, play games, track flights and packages, check the weather and so on.\n",
        "\n",
        "\n",
        "**Siri**\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/700/1*-AuKCZbXIVOhI-AgX4J8PQ.jpeg\">\n",
        "\n",
        "Siri is a virtual assistant of the Apple Inc.’s iOS, watchOS, macOS, HomePod, and tvOS operating systems. Again, you can do a lot of things with voice commands: start a call, text someone, send an email, set a timer, take a picture, open an app, set an alarm, use navigation and so on.\n",
        "\n",
        "### **Applications of NLP:**\n",
        "**Machine Translation**\n",
        "    It is the process by which computer software is used to translate a text from one natural language (such as English) to another (such as Spanish).\n",
        "\n",
        "\n",
        "**Speech Recognition:**\n",
        "    Speech recognition is the process by which a computer (or other type of machine) identifies spoken words. Basically, it means talking to your computer, AND having it correctly recognize what you are saying.\n",
        "    \n",
        "**Sentiment Analysis:**\n",
        "    Sentiment analysis is the process of detecting positive or negative sentiment in text. It’s often used by businesses to detect sentiment in social data, gauge brand reputation, and understand customers.\n",
        "    \n",
        "**Question Answering:**\n",
        "    Question answering (QA) is a computer science discipline within the fields of information retrieval and natural language processing (NLP), which is concerned with building systems that automatically answer questions posed by humans in a natural language.\n",
        "    \n",
        "**Text Summarization:**\n",
        "    Text summarization is the process of distilling the most important information from a source (or sources) to produce an abridged version for a particular user (or users) and task (or tasks).\n",
        "  \n",
        "**Chatbot:**\n",
        "    A chatbot is a software application used to conduct an on-line chat conversation via text or text-to-speech, in lieu of providing direct contact with a live human agent.\n",
        "    \n",
        "**Text Classifications:**\n",
        "    Text clarification is the process of categorizing the text into a group of words. By using NLP, text classification can automatically analyze text and then assign a set of predefined tags or categories based on its context.\n",
        "    \n",
        "**Optical Character Recognition:**\n",
        "    Optical Character Recognition (OCR) is an electronic conversion of the typed, handwritten or printed text images into machine-encoded text\n",
        "    \n",
        "**Spell Checking:**\n",
        "    Spell Checking is a sequence to sequence mapping problem. Given an input sequence, potentially containing a certain number of errors, ContextSpellChecker will rank correction sequences according to three things, Different correction candidates for each word — word level.\n",
        "  \n",
        "**Spam Detection:**\n",
        "    Spam Detection detect unsolicited, unwanted, and virus-infested email (called spam) and stop it from getting into email inboxes.\n",
        "\n",
        "**Named Entity Recognition:**\n",
        "    Named entity recognition (NER) — sometimes referred to as entity chunking, extraction, or identification — is the task of identifying and categorizing key information (entities) in text. An entity can be any word or series of words that consistently refers to the same thing. Every detected entity is classified into a predetermined category. For example, an NER machine learning (ML) model might detect the word “Bdec” in a text and classify it as a “Company”.\n",
        "    \n",
        "    \n",
        "    \n",
        "### **Understanding Natural Language Processing (NLP)**\n",
        "\n",
        "   ![title](https://miro.medium.com/max/581/0*YovzfkM8Ld1LO-87.png)\n",
        "\n",
        "\n",
        "As humans, perform natural language processing (NLP) considerably well, but even then, we are not perfect. We often misunderstand one thing for another, and we often interpret the same sentences or words differently.\n",
        "\n",
        "consider the following sentence,\n",
        "\n",
        "`I saw a man on hill with a telescope.`\n",
        "\n",
        "These are some interpretations of the sentence shown above.\n",
        "   - There is a man on the hill, and I watched him with my telescope.\n",
        "   - There is a man on the hill, and he has a telescope.\n",
        "   - I’m on a hill, and I saw a man using my telescope.\n",
        "   - I’m on a hill, and I saw a man who has a telescope.\n",
        "   - There is a man on a hill, and I saw him something with my telescope.\n",
        "   \n",
        "From the examples above, we can see that language processing is not “deterministic” (the same language has the same interpretations), and something suitable to one person might not be suitable to another.\n",
        "\n",
        "Therefore, Natural Language Processing (NLP) has a non-deterministic approach. In other words, Natural Language Processing can be used to create a new intelligent system that can understand how humans understand and interpret language in different situations.\n",
        "\n",
        "### **Components of Natural Language Processing**\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/455/0*9aT_MdjuT9xXGUdU.png\">\n",
        "\n",
        "**Lexical Analysis:**\n",
        "With lexical analysis, we divide a whole chunk of text into paragraphs, sentences, and words. It involves identifying and analyzing words’ structure.\n",
        "\n",
        "**Syntactic Analysis:**\n",
        "Syntactic analysis involves the analysis of words in a sentence for grammar and arranging words in a manner that shows the relationship among the words. For instance, the sentence “The shop goes to the house” does not pass.\n",
        "\n",
        "**Semantic Analysis:**\n",
        "Semantic analysis draws the exact meaning for the words, and it analyzes the text meaningfulness. Sentences such as “hot ice-cream” do not pass.\n",
        "\n",
        "**Disclosure Integration:**\n",
        "Disclosure integration takes into account the context of the text. It considers the meaning of the sentence before it ends. For example: “He works at Google.” In this sentence, “he” must be referenced in the sentence before it.\n",
        "\n",
        "**Pragmatic Analysis:**\n",
        "Pragmatic analysis deals with overall communication and interpretation of language. It deals with deriving meaningful use of language in various situations.\n",
        "\n",
        "\n",
        "For instance, Banks are using natural language processing (NLP) to automate certain document processing, analysis and customer service activities. Three applications include:\n",
        "\n",
        "- **Intelligent document search:** finding relevant information in large volumes of scanned documents.\n",
        "- **Investment analysis:** automating routine analysis of earnings reports and news so that analysts can focus on alpha generation.\n",
        "- **Customer service & insights:** deploying chatbots to answer customer queries and understand customer needs.\n",
        "\n",
        "![title](https://miro.medium.com/max/2560/1*BqX1wu57y5ApVE-5G-EC4w.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TX2YKeNVsTo"
      },
      "source": [
        "### **NLTK**\n",
        "(Natural Language Toolkit) is a suite that contains libraries and programs for statistical language processing. It is one of the most powerful NLP libraries, which contains packages to make machines understand human language and reply to it with an appropriate response.\n",
        "\n",
        "- if nltk library is not install use pip method to install it.\n",
        "\n",
        "**!pip install nltk**\n",
        "\n",
        "after installation use nltk.download to install all the other packages of nltk.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp--TvUIVsTo"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfuRZs7GVsTp"
      },
      "source": [
        "#nltk.download()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqJG71DvVsTp"
      },
      "source": [
        "## **Text Preprocessing**\n",
        "\n",
        "Since text is the most unstructured form of all the available data, various types of noise are present in it and the data is not readily analyzable without any pre-processing. The entire process of cleaning and standardization of text, making it noise-free and ready for analysis, is known as text preprocessing.\n",
        "\n",
        "\n",
        "![The text data preprocessing framework.](https://www.kdnuggets.com/wp-content/uploads/text-preprocessing-framework-2.png)\n",
        "### **Basic Text Pre-processing of text data**\n",
        "- Case Conversion\n",
        "- Punctuation removal\n",
        "- Stopwords removal\n",
        "- Spelling correction\n",
        "- Tokenization\n",
        "- Stemming\n",
        "- Lemmatization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la7cDuU6VsTp"
      },
      "source": [
        "### **Case Conversion**\n",
        "\n",
        "If the text is in the same case, it is easy for a machine to interpret the words because the lower case and upper case are treated differently by the machine. For example, words like Ball and ball are treated differently by machine. So, we need to make the text in the same case and the most preferred case is a lower case to avoid such problems."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81RWWvfiVsTp",
        "outputId": "30a534b0-e1e1-4bb4-977e-46c02a6e4764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "text='Natural language processing (NLP), describes the interaction between human language and computers.'\n",
        "text"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural language processing (NLP), describes the interaction between human language and computers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59Z1urHfVsTq",
        "outputId": "8be4976c-d491-4097-fd32-316c2b78175d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#conversion of text into lower case.\n",
        "text.lower()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'natural language processing (nlp), describes the interaction between human language and computers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur-mjK1UVsTq",
        "outputId": "39527641-deeb-4343-c29b-5c418d653b5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#conversion of text into upper letter.\n",
        "text.upper()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NATURAL LANGUAGE PROCESSING (NLP), DESCRIBES THE INTERACTION BETWEEN HUMAN LANGUAGE AND COMPUTERS.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er0XIW-ZVsTq"
      },
      "source": [
        "# Load the imdb review dataset\n",
        "import pandas as pd\n",
        "import re\n",
        "imdb=pd.read_csv('imdb_sentiment.csv')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mt4palVEVsTr",
        "outputId": "50bdf21c-1cd9-436c-bbaf-63d41c6e2d30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#converting each review into lower to avoid duplication of word in sentence.\n",
        "imdb['review']=imdb['review'].apply(lambda x :x.lower())\n",
        "imdb['review']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      a very, very, very slow-moving, aimless movie ...\n",
              "1      not sure who was more lost - the flat characte...\n",
              "2      attempting artiness with black & white and cle...\n",
              "3           very little music or anything to speak of.  \n",
              "4      the best scene in the movie was when gerardo i...\n",
              "                             ...                        \n",
              "743    i just got bored watching jessice lange take h...\n",
              "744    unfortunately, any virtue in this film's produ...\n",
              "745                     in a word, it is embarrassing.  \n",
              "746                                 exceptionally bad!  \n",
              "747    all in all its an insult to one's intelligence...\n",
              "Name: review, Length: 748, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8O6rYYeWVsTr"
      },
      "source": [
        "### **Punctuation Removal**\n",
        "One of the other text processing techniques is removing punctuations. There are total 32 main punctuations that need to be taken care of. We can directly use the string module with a regular expression to replace any punctuation in text with an empty string.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:640/format:webp/1*cBCVyPufn4l8lZXjy93s8Q.jpeg\">"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Regex:**\n",
        "\n",
        "A regular expression (regex) is a sequence of characters that defines a search pattern. Here's a guide to writing regular expressions:\n",
        "\n",
        "- **Learn the Special Characters:** Familiarize yourself with special\n",
        "characters used in regex, such as \".\", \"*\", \"+\", \"?\", and others.\n",
        "\n",
        "- **Select a Programming Language or Tool:** Choose a language or tool that supports regex, such as Python, Perl, or grep.\n",
        "\n",
        "- **Construct the Pattern:** Combine special characters with literal characters to form your regex pattern.\n",
        "\n",
        "- **Search for the Pattern:** Use the relevant function or method in your chosen language or tool to search for the pattern in a string.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/0*yEz4_OZ7HhuYNebv.png\">"
      ],
      "metadata": {
        "id": "Czaea7WbDBQH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJzvCFcjVsTr",
        "outputId": "3ebf5911-4f81-41f8-e2cd-e257afcfb679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "#removal of punctuation using regex.\n",
        "text"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural language processing (NLP), describes the interaction between human language and computers.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a30Ooi4mVsTr",
        "outputId": "532b06c9-1464-4ead-fa17-0e84dc560151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "text=re.sub(r'[^\\w\\s]','',text) #remove everything except words and space\n",
        "text"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural language processing NLP describes the interaction between human language and computers'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9jkMye1TVsTs"
      },
      "source": [
        "imdb['clean']=imdb['review'].apply(lambda x : re.sub(r'[^\\w\\s]',' ',x))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-drP0SvVsTs",
        "outputId": "a36821da-3e73-42b2-ffab-0f634d29bd5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imdb['clean']"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      a very  very  very slow moving  aimless movie ...\n",
              "1      not sure who was more lost   the flat characte...\n",
              "2      attempting artiness with black   white and cle...\n",
              "3           very little music or anything to speak of   \n",
              "4      the best scene in the movie was when gerardo i...\n",
              "                             ...                        \n",
              "743    i just got bored watching jessice lange take h...\n",
              "744    unfortunately  any virtue in this film s produ...\n",
              "745                     in a word  it is embarrassing   \n",
              "746                                 exceptionally bad   \n",
              "747    all in all its an insult to one s intelligence...\n",
              "Name: clean, Length: 748, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhwDw_uFVsTs"
      },
      "source": [
        "#remove punctuation using string module\n",
        "import string\n",
        "imdb['clean1']=imdb['review'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '' , x))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvIWkR2OVsTs",
        "outputId": "7d803197-cd02-4695-e086-1be129ef3f8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imdb['clean1']"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      a very very very slowmoving aimless movie abou...\n",
              "1      not sure who was more lost  the flat character...\n",
              "2      attempting artiness with black  white and clev...\n",
              "3            very little music or anything to speak of  \n",
              "4      the best scene in the movie was when gerardo i...\n",
              "                             ...                        \n",
              "743    i just got bored watching jessice lange take h...\n",
              "744    unfortunately any virtue in this films product...\n",
              "745                       in a word it is embarrassing  \n",
              "746                                  exceptionally bad  \n",
              "747    all in all its an insult to ones intelligence ...\n",
              "Name: clean1, Length: 748, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Stopword Removal**"
      ],
      "metadata": {
        "id": "0hxct89KG4VU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD9eizF7VsTt"
      },
      "source": [
        "### **What are stop words?**\n",
        "\n",
        "Stopwords are the words in any language which does not add much meaning to a sentence. They can be safely ignored without sacrificing the meaning of the sentence. For some search engines, these are some of the most common, short function words, such as the, is, at, which, and on. In this case, stop words can cause problems when searching for phrases that include them, particularly in names such as “The Who” or “Take That”.\n",
        "\n",
        "<img src=\"https://repository-images.githubusercontent.com/181882059/cfeb9180-6dde-11e9-85b6-e79357766310\" height=\"400\" width=\"600\">\n",
        "\n",
        "\n",
        "### **When to remove stop words?**\n",
        "\n",
        "If we have a task of text classification or sentiment analysis then we should remove stop words as they do not provide any information to our model, i.e keeping out unwanted words out of our corpus, but if we have the task of language translation then stopwords are useful, as they have to be translated along with other words.\n",
        "\n",
        "There is no hard and fast rule on when to remove stop words. But I would suggest removing stop words if our task to be performed is one of Language Classification, Spam Filtering, Caption Generation, Auto-Tag Generation, Sentiment analysis, or something that is related to text classification.\n",
        "\n",
        "On the other hand, if our task is one of Machine Translation, Question-Answering problems, Text Summarization, Language Modeling, it’s better not to remove the stop words as they are a crucial part of these applications.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's remove stopwords"
      ],
      "metadata": {
        "id": "XCg1RdImG9YE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBwt2PvOVsTt",
        "outputId": "147c1ee5-dbaa-4528-ad7a-91d2e435b389",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')\n",
        "print('This are the stopwords',stop)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This are the stopwords ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g_R9h2bVsTt",
        "outputId": "cf77853f-b99f-4291-bd94-783f52bdc918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "text"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural language processing NLP describes the interaction between human language and computers'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZVuzkO-VsTu",
        "outputId": "cbdb27f8-4471-4803-bd9e-4a86d6666651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "text=' '.join([x for x in text.split() if x not in stop]) #here we are spltting the text and then removing the stop word from list\n",
        "#and theb join the list to string.\n",
        "text"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Natural language processing NLP describes interaction human language computers'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ws0e4lroVsTu",
        "outputId": "e68f9855-c68b-4202-ed25-4d96239d2955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#removing stop words from reviews.\n",
        "imdb['clean']=imdb['clean'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "imdb['clean']"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      slow moving aimless movie distressed drifting ...\n",
              "1      sure lost flat characters audience nearly half...\n",
              "2      attempting artiness black white clever camera ...\n",
              "3                            little music anything speak\n",
              "4      best scene movie gerardo trying find song keep...\n",
              "                             ...                        \n",
              "743        got bored watching jessice lange take clothes\n",
              "744    unfortunately virtue film production work lost...\n",
              "745                                    word embarrassing\n",
              "746                                    exceptionally bad\n",
              "747             insult one intelligence huge waste money\n",
              "Name: clean, Length: 748, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6L1Do6kVsTu"
      },
      "source": [
        "- Now we can see that stop words like `\"very\", \"a\"` is removed from the review."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xArLXceoVsTu"
      },
      "source": [
        "### **Spell checks**\n",
        "\n",
        "Spelling mistakes are common and most of us are used to software indicating if a mistake was made or not. From autocorrect on our phones to red underlining in text editors, spell checking is an essential feature for many different products.\n",
        "\n",
        "<img src=\"https://www.gingersoftware.com/statics/2.3.16/images/uploads/Group-541.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AG1uSfpWVsTu"
      },
      "source": [
        "# Many a time some words are spelt wrongly by author either by mistake or due to typing error\n",
        "# So corpus of our word increases due to wrong spellings, hence we correct them\n",
        "# We will use textBlob module.\n",
        "# If textBlob is not installed use pip method to install it.\n",
        "#!pip install textblob\n",
        "from textblob import TextBlob"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybWjRKl7VsTv"
      },
      "source": [
        "text_='hostipal is far'# here spelling of hospital is worng."
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAG_tKo2VsTv"
      },
      "source": [
        "- The correct() Function\n",
        "- The most straightforward way to correct input text is to use the correct() method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PoqIUqdVsTv",
        "outputId": "c313b400-67c4-4e7d-a328-25e8b744e9d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text_=TextBlob(text_).correct() # from textblob we use correct to corrrect the spellings.\n",
        "text_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TextBlob(\"hospital is far\")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sv0xC7Q-VsTv",
        "outputId": "6b5ee954-f9fb-4b6d-d272-0670d60fcfb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# same way we can use for reviews\n",
        "imdb['clean'][:10].apply(lambda x: str(TextBlob(x).correct()))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    slow moving aimless movie distressed drifting ...\n",
              "1    sure lost flat characters audience nearly half...\n",
              "2    attempting artless black white clever camera a...\n",
              "3                          little music anything speak\n",
              "4    best scene movie gerard trying find song keeps...\n",
              "5    rest movie lacks art charm meaning emptiness w...\n",
              "6                                     wasted two hours\n",
              "7    saw movie today thought good effort good messa...\n",
              "8                                      bit predictable\n",
              "9          loved casting jimmy buffets science teacher\n",
              "Name: clean, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k16a4MYVVsTv"
      },
      "source": [
        "## **Tokenization**\n",
        "\n",
        "Tokenization is splitting the large chunk of word, sentence, document into smaller unit (single word or combination of words). Smaller units are known as tokens.\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*PZYP2nL6Zc_jpkaHLRxLQQ.png\" height=\"300\" width=\"500\">\n",
        "\n",
        "\n",
        "**Why is Tokenization required in NLP?**\n",
        "\n",
        "Before processing a natural language, we need to identify the words that constitute a string of characters. That’s why tokenization is the most basic step to proceed with NLP (text data). This is important because the meaning of the text could easily be interpreted by analyzing the words present in the text.\n",
        "\n",
        "**Tokenization using split()**\n",
        "\n",
        "Let’s start with the split() method as it is the most basic one. It returns a list of strings after breaking the given string by the specified separator. By default, split() breaks a string at each space. We can change the separator to anything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZN5VCTjVsTw",
        "outputId": "e70b6fa5-56a2-4a77-ada2-b50a4f160073",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Split is the most basic tokenizing technique.here we splited on the whitespaces. It split and return the list of all the words.\n",
        "Text=\"\"\"Because of problems with her eyesight, rey the African penguin had issues with swimming. That’s unusual for a penguin,\n",
        "and presented a big challenge for our aviculture team to help Rey overcome her hesitancy.\n",
        "Slowly and steadily, we trained her to be comfortable feeding in the water like the rest of the penguin colony.\n",
        "The aviculturists also trained Rey to accept daily eye drops from them as part of her special health care.\n",
        "Rey already had good relationships with some staff, and was comfortable with them handling her.\n",
        "Senior Aviculturist Kim Fukuda says the team built on those bonds to get Rey used to receiving the eye drops.\n",
        "\"She knows the routine,\" Kim says. \"I usually give her the eye drops in one area of the exhibit after all the penguins get\n",
        "their vitamins. When that happens, she runs over there and waits for me.\" Rosa, our oldest sea otter, has very limited eyesight,\n",
        "among other health issues. The sea otter team had already trained Rosa so they could examine her eyes,\n",
        "and built on that trust to include administering the eye drops she needs.\"\"\"\n",
        "Text.split()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Because',\n",
              " 'of',\n",
              " 'problems',\n",
              " 'with',\n",
              " 'her',\n",
              " 'eyesight,',\n",
              " 'rey',\n",
              " 'the',\n",
              " 'African',\n",
              " 'penguin',\n",
              " 'had',\n",
              " 'issues',\n",
              " 'with',\n",
              " 'swimming.',\n",
              " 'That’s',\n",
              " 'unusual',\n",
              " 'for',\n",
              " 'a',\n",
              " 'penguin,',\n",
              " 'and',\n",
              " 'presented',\n",
              " 'a',\n",
              " 'big',\n",
              " 'challenge',\n",
              " 'for',\n",
              " 'our',\n",
              " 'aviculture',\n",
              " 'team',\n",
              " 'to',\n",
              " 'help',\n",
              " 'Rey',\n",
              " 'overcome',\n",
              " 'her',\n",
              " 'hesitancy.',\n",
              " 'Slowly',\n",
              " 'and',\n",
              " 'steadily,',\n",
              " 'we',\n",
              " 'trained',\n",
              " 'her',\n",
              " 'to',\n",
              " 'be',\n",
              " 'comfortable',\n",
              " 'feeding',\n",
              " 'in',\n",
              " 'the',\n",
              " 'water',\n",
              " 'like',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'penguin',\n",
              " 'colony.',\n",
              " 'The',\n",
              " 'aviculturists',\n",
              " 'also',\n",
              " 'trained',\n",
              " 'Rey',\n",
              " 'to',\n",
              " 'accept',\n",
              " 'daily',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'from',\n",
              " 'them',\n",
              " 'as',\n",
              " 'part',\n",
              " 'of',\n",
              " 'her',\n",
              " 'special',\n",
              " 'health',\n",
              " 'care.',\n",
              " 'Rey',\n",
              " 'already',\n",
              " 'had',\n",
              " 'good',\n",
              " 'relationships',\n",
              " 'with',\n",
              " 'some',\n",
              " 'staff,',\n",
              " 'and',\n",
              " 'was',\n",
              " 'comfortable',\n",
              " 'with',\n",
              " 'them',\n",
              " 'handling',\n",
              " 'her.',\n",
              " 'Senior',\n",
              " 'Aviculturist',\n",
              " 'Kim',\n",
              " 'Fukuda',\n",
              " 'says',\n",
              " 'the',\n",
              " 'team',\n",
              " 'built',\n",
              " 'on',\n",
              " 'those',\n",
              " 'bonds',\n",
              " 'to',\n",
              " 'get',\n",
              " 'Rey',\n",
              " 'used',\n",
              " 'to',\n",
              " 'receiving',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops.',\n",
              " '\"She',\n",
              " 'knows',\n",
              " 'the',\n",
              " 'routine,\"',\n",
              " 'Kim',\n",
              " 'says.',\n",
              " '\"I',\n",
              " 'usually',\n",
              " 'give',\n",
              " 'her',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'in',\n",
              " 'one',\n",
              " 'area',\n",
              " 'of',\n",
              " 'the',\n",
              " 'exhibit',\n",
              " 'after',\n",
              " 'all',\n",
              " 'the',\n",
              " 'penguins',\n",
              " 'get',\n",
              " 'their',\n",
              " 'vitamins.',\n",
              " 'When',\n",
              " 'that',\n",
              " 'happens,',\n",
              " 'she',\n",
              " 'runs',\n",
              " 'over',\n",
              " 'there',\n",
              " 'and',\n",
              " 'waits',\n",
              " 'for',\n",
              " 'me.\"',\n",
              " 'Rosa,',\n",
              " 'our',\n",
              " 'oldest',\n",
              " 'sea',\n",
              " 'otter,',\n",
              " 'has',\n",
              " 'very',\n",
              " 'limited',\n",
              " 'eyesight,',\n",
              " 'among',\n",
              " 'other',\n",
              " 'health',\n",
              " 'issues.',\n",
              " 'The',\n",
              " 'sea',\n",
              " 'otter',\n",
              " 'team',\n",
              " 'had',\n",
              " 'already',\n",
              " 'trained',\n",
              " 'Rosa',\n",
              " 'so',\n",
              " 'they',\n",
              " 'could',\n",
              " 'examine',\n",
              " 'her',\n",
              " 'eyes,',\n",
              " 'and',\n",
              " 'built',\n",
              " 'on',\n",
              " 'that',\n",
              " 'trust',\n",
              " 'to',\n",
              " 'include',\n",
              " 'administering',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'she',\n",
              " 'needs.']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-b0YKitVsTw"
      },
      "source": [
        "### **Tokenization using regex.**\n",
        "\n",
        "The re.findall() function finds all the words that match the pattern passed on it and stores it in the list.\n",
        "The “\\w” represents “any word character” which usually means alphanumeric (letters, numbers) and underscore (_). ‘+’ means any number of times. So [\\w’]+ signals that the code should find all the alphanumeric characters until any other character is encountered."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUb2vTAoVsTw",
        "outputId": "9a770f77-7416-484f-d86d-c047068876ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# we will use re library in Python to work with regular expression.\n",
        "tokens = re.findall(\"[\\w']+\", Text)\n",
        "tokens"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Because',\n",
              " 'of',\n",
              " 'problems',\n",
              " 'with',\n",
              " 'her',\n",
              " 'eyesight',\n",
              " 'rey',\n",
              " 'the',\n",
              " 'African',\n",
              " 'penguin',\n",
              " 'had',\n",
              " 'issues',\n",
              " 'with',\n",
              " 'swimming',\n",
              " 'That',\n",
              " 's',\n",
              " 'unusual',\n",
              " 'for',\n",
              " 'a',\n",
              " 'penguin',\n",
              " 'and',\n",
              " 'presented',\n",
              " 'a',\n",
              " 'big',\n",
              " 'challenge',\n",
              " 'for',\n",
              " 'our',\n",
              " 'aviculture',\n",
              " 'team',\n",
              " 'to',\n",
              " 'help',\n",
              " 'Rey',\n",
              " 'overcome',\n",
              " 'her',\n",
              " 'hesitancy',\n",
              " 'Slowly',\n",
              " 'and',\n",
              " 'steadily',\n",
              " 'we',\n",
              " 'trained',\n",
              " 'her',\n",
              " 'to',\n",
              " 'be',\n",
              " 'comfortable',\n",
              " 'feeding',\n",
              " 'in',\n",
              " 'the',\n",
              " 'water',\n",
              " 'like',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'penguin',\n",
              " 'colony',\n",
              " 'The',\n",
              " 'aviculturists',\n",
              " 'also',\n",
              " 'trained',\n",
              " 'Rey',\n",
              " 'to',\n",
              " 'accept',\n",
              " 'daily',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'from',\n",
              " 'them',\n",
              " 'as',\n",
              " 'part',\n",
              " 'of',\n",
              " 'her',\n",
              " 'special',\n",
              " 'health',\n",
              " 'care',\n",
              " 'Rey',\n",
              " 'already',\n",
              " 'had',\n",
              " 'good',\n",
              " 'relationships',\n",
              " 'with',\n",
              " 'some',\n",
              " 'staff',\n",
              " 'and',\n",
              " 'was',\n",
              " 'comfortable',\n",
              " 'with',\n",
              " 'them',\n",
              " 'handling',\n",
              " 'her',\n",
              " 'Senior',\n",
              " 'Aviculturist',\n",
              " 'Kim',\n",
              " 'Fukuda',\n",
              " 'says',\n",
              " 'the',\n",
              " 'team',\n",
              " 'built',\n",
              " 'on',\n",
              " 'those',\n",
              " 'bonds',\n",
              " 'to',\n",
              " 'get',\n",
              " 'Rey',\n",
              " 'used',\n",
              " 'to',\n",
              " 'receiving',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'She',\n",
              " 'knows',\n",
              " 'the',\n",
              " 'routine',\n",
              " 'Kim',\n",
              " 'says',\n",
              " 'I',\n",
              " 'usually',\n",
              " 'give',\n",
              " 'her',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'in',\n",
              " 'one',\n",
              " 'area',\n",
              " 'of',\n",
              " 'the',\n",
              " 'exhibit',\n",
              " 'after',\n",
              " 'all',\n",
              " 'the',\n",
              " 'penguins',\n",
              " 'get',\n",
              " 'their',\n",
              " 'vitamins',\n",
              " 'When',\n",
              " 'that',\n",
              " 'happens',\n",
              " 'she',\n",
              " 'runs',\n",
              " 'over',\n",
              " 'there',\n",
              " 'and',\n",
              " 'waits',\n",
              " 'for',\n",
              " 'me',\n",
              " 'Rosa',\n",
              " 'our',\n",
              " 'oldest',\n",
              " 'sea',\n",
              " 'otter',\n",
              " 'has',\n",
              " 'very',\n",
              " 'limited',\n",
              " 'eyesight',\n",
              " 'among',\n",
              " 'other',\n",
              " 'health',\n",
              " 'issues',\n",
              " 'The',\n",
              " 'sea',\n",
              " 'otter',\n",
              " 'team',\n",
              " 'had',\n",
              " 'already',\n",
              " 'trained',\n",
              " 'Rosa',\n",
              " 'so',\n",
              " 'they',\n",
              " 'could',\n",
              " 'examine',\n",
              " 'her',\n",
              " 'eyes',\n",
              " 'and',\n",
              " 'built',\n",
              " 'on',\n",
              " 'that',\n",
              " 'trust',\n",
              " 'to',\n",
              " 'include',\n",
              " 'administering',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'she',\n",
              " 'needs']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aZdktuNVsTw"
      },
      "source": [
        "- The re.findall() function finds all the words that match the pattern passed on it and stores it in the list.\n",
        "-  The “\\w” represents “any word character” which usually means alphanumeric (letters, numbers) and underscore (_). ‘+’ means any number of times."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4TD-fuTVsTx"
      },
      "source": [
        "### **Tokenization using NLTK**\n",
        "\n",
        "NLTK contains a module called tokenize() which further classifies into two sub-categories:\n",
        "\n",
        "- Word tokenize: We use the word_tokenize() method to split a sentence into tokens or words.\n",
        "- Sentence tokenize: We use the sent_tokenize() method to split a document or paragraph into sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MhEJGcnGVsTx",
        "outputId": "fb2d157d-c977-4b20-9aed-b0b0633561a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Tokenize module have further 2 module. word_tokenize, sentence_tokenize.\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "token=word_tokenize(Text)\n",
        "token"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Because',\n",
              " 'of',\n",
              " 'problems',\n",
              " 'with',\n",
              " 'her',\n",
              " 'eyesight',\n",
              " ',',\n",
              " 'rey',\n",
              " 'the',\n",
              " 'African',\n",
              " 'penguin',\n",
              " 'had',\n",
              " 'issues',\n",
              " 'with',\n",
              " 'swimming',\n",
              " '.',\n",
              " 'That',\n",
              " '’',\n",
              " 's',\n",
              " 'unusual',\n",
              " 'for',\n",
              " 'a',\n",
              " 'penguin',\n",
              " ',',\n",
              " 'and',\n",
              " 'presented',\n",
              " 'a',\n",
              " 'big',\n",
              " 'challenge',\n",
              " 'for',\n",
              " 'our',\n",
              " 'aviculture',\n",
              " 'team',\n",
              " 'to',\n",
              " 'help',\n",
              " 'Rey',\n",
              " 'overcome',\n",
              " 'her',\n",
              " 'hesitancy',\n",
              " '.',\n",
              " 'Slowly',\n",
              " 'and',\n",
              " 'steadily',\n",
              " ',',\n",
              " 'we',\n",
              " 'trained',\n",
              " 'her',\n",
              " 'to',\n",
              " 'be',\n",
              " 'comfortable',\n",
              " 'feeding',\n",
              " 'in',\n",
              " 'the',\n",
              " 'water',\n",
              " 'like',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'penguin',\n",
              " 'colony',\n",
              " '.',\n",
              " 'The',\n",
              " 'aviculturists',\n",
              " 'also',\n",
              " 'trained',\n",
              " 'Rey',\n",
              " 'to',\n",
              " 'accept',\n",
              " 'daily',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'from',\n",
              " 'them',\n",
              " 'as',\n",
              " 'part',\n",
              " 'of',\n",
              " 'her',\n",
              " 'special',\n",
              " 'health',\n",
              " 'care',\n",
              " '.',\n",
              " 'Rey',\n",
              " 'already',\n",
              " 'had',\n",
              " 'good',\n",
              " 'relationships',\n",
              " 'with',\n",
              " 'some',\n",
              " 'staff',\n",
              " ',',\n",
              " 'and',\n",
              " 'was',\n",
              " 'comfortable',\n",
              " 'with',\n",
              " 'them',\n",
              " 'handling',\n",
              " 'her',\n",
              " '.',\n",
              " 'Senior',\n",
              " 'Aviculturist',\n",
              " 'Kim',\n",
              " 'Fukuda',\n",
              " 'says',\n",
              " 'the',\n",
              " 'team',\n",
              " 'built',\n",
              " 'on',\n",
              " 'those',\n",
              " 'bonds',\n",
              " 'to',\n",
              " 'get',\n",
              " 'Rey',\n",
              " 'used',\n",
              " 'to',\n",
              " 'receiving',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " '.',\n",
              " '``',\n",
              " 'She',\n",
              " 'knows',\n",
              " 'the',\n",
              " 'routine',\n",
              " ',',\n",
              " \"''\",\n",
              " 'Kim',\n",
              " 'says',\n",
              " '.',\n",
              " '``',\n",
              " 'I',\n",
              " 'usually',\n",
              " 'give',\n",
              " 'her',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'in',\n",
              " 'one',\n",
              " 'area',\n",
              " 'of',\n",
              " 'the',\n",
              " 'exhibit',\n",
              " 'after',\n",
              " 'all',\n",
              " 'the',\n",
              " 'penguins',\n",
              " 'get',\n",
              " 'their',\n",
              " 'vitamins',\n",
              " '.',\n",
              " 'When',\n",
              " 'that',\n",
              " 'happens',\n",
              " ',',\n",
              " 'she',\n",
              " 'runs',\n",
              " 'over',\n",
              " 'there',\n",
              " 'and',\n",
              " 'waits',\n",
              " 'for',\n",
              " 'me',\n",
              " '.',\n",
              " \"''\",\n",
              " 'Rosa',\n",
              " ',',\n",
              " 'our',\n",
              " 'oldest',\n",
              " 'sea',\n",
              " 'otter',\n",
              " ',',\n",
              " 'has',\n",
              " 'very',\n",
              " 'limited',\n",
              " 'eyesight',\n",
              " ',',\n",
              " 'among',\n",
              " 'other',\n",
              " 'health',\n",
              " 'issues',\n",
              " '.',\n",
              " 'The',\n",
              " 'sea',\n",
              " 'otter',\n",
              " 'team',\n",
              " 'had',\n",
              " 'already',\n",
              " 'trained',\n",
              " 'Rosa',\n",
              " 'so',\n",
              " 'they',\n",
              " 'could',\n",
              " 'examine',\n",
              " 'her',\n",
              " 'eyes',\n",
              " ',',\n",
              " 'and',\n",
              " 'built',\n",
              " 'on',\n",
              " 'that',\n",
              " 'trust',\n",
              " 'to',\n",
              " 'include',\n",
              " 'administering',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'she',\n",
              " 'needs',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBdYwqp3VsTx"
      },
      "source": [
        "- NLTK consider punctuation as tokens. so we can remove the punctuation for further use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChKfWgsfVsTx"
      },
      "source": [
        "### **Tokenization using the spaCy library**\n",
        "\n",
        "spaCy is an open-source library for advanced Natural Language Processing (NLP). It supports over 49+ languages and provides state-of-the-art computation speed.\n",
        "- Spacy is faster than its other contenders\n",
        "\n",
        "Installation of Spacy\n",
        "\n",
        "**pip install -U pip setuptools wheel**\n",
        "\n",
        "**pip install -U spacy**\n",
        "\n",
        "**python -m spacy download en_core_web_sm**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYMmMXh8VsTz"
      },
      "source": [
        "# if spacy is not installed, use pip method to install it\n",
        "# import library.\n",
        "from spacy.lang.en import English\n",
        "# Load English tokenizer\n",
        "nlp = English()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dga7RxEZVsT0",
        "outputId": "67295a6b-a41e-45b8-d257-f4ff1770a70c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "my_doc = nlp(Text)\n",
        "# Create list of word tokens\n",
        "token_list = []\n",
        "for token in my_doc:\n",
        "    token_list.append(token.text)\n",
        "token_list"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Because',\n",
              " 'of',\n",
              " 'problems',\n",
              " 'with',\n",
              " 'her',\n",
              " 'eyesight',\n",
              " ',',\n",
              " 'rey',\n",
              " 'the',\n",
              " 'African',\n",
              " 'penguin',\n",
              " 'had',\n",
              " 'issues',\n",
              " 'with',\n",
              " 'swimming',\n",
              " '.',\n",
              " 'That',\n",
              " '’s',\n",
              " 'unusual',\n",
              " 'for',\n",
              " 'a',\n",
              " 'penguin',\n",
              " ',',\n",
              " '\\n',\n",
              " 'and',\n",
              " 'presented',\n",
              " 'a',\n",
              " 'big',\n",
              " 'challenge',\n",
              " 'for',\n",
              " 'our',\n",
              " 'aviculture',\n",
              " 'team',\n",
              " 'to',\n",
              " 'help',\n",
              " 'Rey',\n",
              " 'overcome',\n",
              " 'her',\n",
              " 'hesitancy',\n",
              " '.',\n",
              " '\\n',\n",
              " 'Slowly',\n",
              " 'and',\n",
              " 'steadily',\n",
              " ',',\n",
              " 'we',\n",
              " 'trained',\n",
              " 'her',\n",
              " 'to',\n",
              " 'be',\n",
              " 'comfortable',\n",
              " 'feeding',\n",
              " 'in',\n",
              " 'the',\n",
              " 'water',\n",
              " 'like',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'penguin',\n",
              " 'colony',\n",
              " '.',\n",
              " '\\n',\n",
              " 'The',\n",
              " 'aviculturists',\n",
              " 'also',\n",
              " 'trained',\n",
              " 'Rey',\n",
              " 'to',\n",
              " 'accept',\n",
              " 'daily',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'from',\n",
              " 'them',\n",
              " 'as',\n",
              " 'part',\n",
              " 'of',\n",
              " 'her',\n",
              " 'special',\n",
              " 'health',\n",
              " 'care',\n",
              " '.',\n",
              " '\\n',\n",
              " 'Rey',\n",
              " 'already',\n",
              " 'had',\n",
              " 'good',\n",
              " 'relationships',\n",
              " 'with',\n",
              " 'some',\n",
              " 'staff',\n",
              " ',',\n",
              " 'and',\n",
              " 'was',\n",
              " 'comfortable',\n",
              " 'with',\n",
              " 'them',\n",
              " 'handling',\n",
              " 'her',\n",
              " '.',\n",
              " '\\n',\n",
              " 'Senior',\n",
              " 'Aviculturist',\n",
              " 'Kim',\n",
              " 'Fukuda',\n",
              " 'says',\n",
              " 'the',\n",
              " 'team',\n",
              " 'built',\n",
              " 'on',\n",
              " 'those',\n",
              " 'bonds',\n",
              " 'to',\n",
              " 'get',\n",
              " 'Rey',\n",
              " 'used',\n",
              " 'to',\n",
              " 'receiving',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " '.',\n",
              " '\\n',\n",
              " '\"',\n",
              " 'She',\n",
              " 'knows',\n",
              " 'the',\n",
              " 'routine',\n",
              " ',',\n",
              " '\"',\n",
              " 'Kim',\n",
              " 'says',\n",
              " '.',\n",
              " '\"',\n",
              " 'I',\n",
              " 'usually',\n",
              " 'give',\n",
              " 'her',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'in',\n",
              " 'one',\n",
              " 'area',\n",
              " 'of',\n",
              " 'the',\n",
              " 'exhibit',\n",
              " 'after',\n",
              " 'all',\n",
              " 'the',\n",
              " 'penguins',\n",
              " 'get',\n",
              " '\\n',\n",
              " 'their',\n",
              " 'vitamins',\n",
              " '.',\n",
              " 'When',\n",
              " 'that',\n",
              " 'happens',\n",
              " ',',\n",
              " 'she',\n",
              " 'runs',\n",
              " 'over',\n",
              " 'there',\n",
              " 'and',\n",
              " 'waits',\n",
              " 'for',\n",
              " 'me',\n",
              " '.',\n",
              " '\"',\n",
              " 'Rosa',\n",
              " ',',\n",
              " 'our',\n",
              " 'oldest',\n",
              " 'sea',\n",
              " 'otter',\n",
              " ',',\n",
              " 'has',\n",
              " 'very',\n",
              " 'limited',\n",
              " 'eyesight',\n",
              " ',',\n",
              " '\\n',\n",
              " 'among',\n",
              " 'other',\n",
              " 'health',\n",
              " 'issues',\n",
              " '.',\n",
              " 'The',\n",
              " 'sea',\n",
              " 'otter',\n",
              " 'team',\n",
              " 'had',\n",
              " 'already',\n",
              " 'trained',\n",
              " 'Rosa',\n",
              " 'so',\n",
              " 'they',\n",
              " 'could',\n",
              " 'examine',\n",
              " 'her',\n",
              " 'eyes',\n",
              " ',',\n",
              " '\\n',\n",
              " 'and',\n",
              " 'built',\n",
              " 'on',\n",
              " 'that',\n",
              " 'trust',\n",
              " 'to',\n",
              " 'include',\n",
              " 'administering',\n",
              " 'the',\n",
              " 'eye',\n",
              " 'drops',\n",
              " 'she',\n",
              " 'needs',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aF18Nt1VsT0",
        "outputId": "e1d0d441-8239-4ef6-8fff-5a611c88bd3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#tokenizing the reviews of imdb datasets.\n",
        "review=' '.join(imdb['review'])\n",
        "my_doc = nlp(review)\n",
        "# Create list of word tokens\n",
        "token_list = []\n",
        "for token in my_doc:\n",
        "    token_list.append(token.text)\n",
        "token_list"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'very',\n",
              " ',',\n",
              " 'very',\n",
              " ',',\n",
              " 'very',\n",
              " 'slow',\n",
              " '-',\n",
              " 'moving',\n",
              " ',',\n",
              " 'aimless',\n",
              " 'movie',\n",
              " 'about',\n",
              " 'a',\n",
              " 'distressed',\n",
              " ',',\n",
              " 'drifting',\n",
              " 'young',\n",
              " 'man',\n",
              " '.',\n",
              " '  ',\n",
              " 'not',\n",
              " 'sure',\n",
              " 'who',\n",
              " 'was',\n",
              " 'more',\n",
              " 'lost',\n",
              " '-',\n",
              " 'the',\n",
              " 'flat',\n",
              " 'characters',\n",
              " 'or',\n",
              " 'the',\n",
              " 'audience',\n",
              " ',',\n",
              " 'nearly',\n",
              " 'half',\n",
              " 'of',\n",
              " 'whom',\n",
              " 'walked',\n",
              " 'out',\n",
              " '.',\n",
              " '  ',\n",
              " 'attempting',\n",
              " 'artiness',\n",
              " 'with',\n",
              " 'black',\n",
              " '&',\n",
              " 'white',\n",
              " 'and',\n",
              " 'clever',\n",
              " 'camera',\n",
              " 'angles',\n",
              " ',',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'disappointed',\n",
              " '-',\n",
              " 'became',\n",
              " 'even',\n",
              " 'more',\n",
              " 'ridiculous',\n",
              " '-',\n",
              " 'as',\n",
              " 'the',\n",
              " 'acting',\n",
              " 'was',\n",
              " 'poor',\n",
              " 'and',\n",
              " 'the',\n",
              " 'plot',\n",
              " 'and',\n",
              " 'lines',\n",
              " 'almost',\n",
              " 'non',\n",
              " '-',\n",
              " 'existent',\n",
              " '.',\n",
              " '  ',\n",
              " 'very',\n",
              " 'little',\n",
              " 'music',\n",
              " 'or',\n",
              " 'anything',\n",
              " 'to',\n",
              " 'speak',\n",
              " 'of',\n",
              " '.',\n",
              " '  ',\n",
              " 'the',\n",
              " 'best',\n",
              " 'scene',\n",
              " 'in',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'was',\n",
              " 'when',\n",
              " 'gerardo',\n",
              " 'is',\n",
              " 'trying',\n",
              " 'to',\n",
              " 'find',\n",
              " 'a',\n",
              " 'song',\n",
              " 'that',\n",
              " 'keeps',\n",
              " 'running',\n",
              " 'through',\n",
              " 'his',\n",
              " 'head',\n",
              " '.',\n",
              " '  ',\n",
              " 'the',\n",
              " 'rest',\n",
              " 'of',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'lacks',\n",
              " 'art',\n",
              " ',',\n",
              " 'charm',\n",
              " ',',\n",
              " 'meaning',\n",
              " '...',\n",
              " 'if',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'about',\n",
              " 'emptiness',\n",
              " ',',\n",
              " 'it',\n",
              " 'works',\n",
              " 'i',\n",
              " 'guess',\n",
              " 'because',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'empty',\n",
              " '.',\n",
              " '  ',\n",
              " 'wasted',\n",
              " 'two',\n",
              " 'hours',\n",
              " '.',\n",
              " '  ',\n",
              " 'saw',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'today',\n",
              " 'and',\n",
              " 'thought',\n",
              " 'it',\n",
              " 'was',\n",
              " 'a',\n",
              " 'good',\n",
              " 'effort',\n",
              " ',',\n",
              " 'good',\n",
              " 'messages',\n",
              " 'for',\n",
              " 'kids',\n",
              " '.',\n",
              " '  ',\n",
              " 'a',\n",
              " 'bit',\n",
              " 'predictable',\n",
              " '.',\n",
              " '  ',\n",
              " 'loved',\n",
              " 'the',\n",
              " 'casting',\n",
              " 'of',\n",
              " 'jimmy',\n",
              " 'buffet',\n",
              " 'as',\n",
              " 'the',\n",
              " 'science',\n",
              " 'teacher',\n",
              " '.',\n",
              " '  ',\n",
              " 'and',\n",
              " 'those',\n",
              " 'baby',\n",
              " 'owls',\n",
              " 'were',\n",
              " 'adorable',\n",
              " '.',\n",
              " '  ',\n",
              " 'the',\n",
              " 'movie',\n",
              " 'showed',\n",
              " 'a',\n",
              " 'lot',\n",
              " 'of',\n",
              " 'florida',\n",
              " 'at',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'best',\n",
              " ',',\n",
              " 'made',\n",
              " 'it',\n",
              " 'look',\n",
              " 'very',\n",
              " 'appealing',\n",
              " '.',\n",
              " '  ',\n",
              " 'the',\n",
              " 'songs',\n",
              " 'were',\n",
              " 'the',\n",
              " 'best',\n",
              " 'and',\n",
              " 'the',\n",
              " 'muppets',\n",
              " 'were',\n",
              " 'so',\n",
              " 'hilarious',\n",
              " '.',\n",
              " '  ',\n",
              " 'it',\n",
              " 'was',\n",
              " 'so',\n",
              " 'cool',\n",
              " '.',\n",
              " '  ',\n",
              " 'this',\n",
              " 'is',\n",
              " 'a',\n",
              " 'very',\n",
              " '\"',\n",
              " 'right',\n",
              " 'on',\n",
              " 'case',\n",
              " '\"',\n",
              " 'movie',\n",
              " 'that',\n",
              " 'delivers',\n",
              " 'everything',\n",
              " 'almost',\n",
              " 'right',\n",
              " 'in',\n",
              " 'your',\n",
              " 'face',\n",
              " '.',\n",
              " '  ',\n",
              " 'it',\n",
              " 'had',\n",
              " 'some',\n",
              " 'average',\n",
              " 'acting',\n",
              " 'from',\n",
              " 'the',\n",
              " 'main',\n",
              " 'person',\n",
              " ',',\n",
              " 'and',\n",
              " 'it',\n",
              " 'was',\n",
              " 'a',\n",
              " 'low',\n",
              " 'budget',\n",
              " 'as',\n",
              " 'you',\n",
              " 'clearly',\n",
              " 'can',\n",
              " 'see',\n",
              " '.',\n",
              " '  ',\n",
              " 'this',\n",
              " 'review',\n",
              " 'is',\n",
              " 'long',\n",
              " 'overdue',\n",
              " ',',\n",
              " 'since',\n",
              " 'i',\n",
              " 'consider',\n",
              " 'a',\n",
              " 'tale',\n",
              " 'of',\n",
              " 'two',\n",
              " 'sisters',\n",
              " 'to',\n",
              " 'be',\n",
              " 'the',\n",
              " 'single',\n",
              " 'greatest',\n",
              " 'film',\n",
              " 'ever',\n",
              " 'made',\n",
              " '.',\n",
              " '  ',\n",
              " 'i',\n",
              " \"'ll\",\n",
              " 'put',\n",
              " 'this',\n",
              " 'gem',\n",
              " 'up',\n",
              " 'against',\n",
              " 'any',\n",
              " 'movie',\n",
              " 'in',\n",
              " 'terms',\n",
              " 'of',\n",
              " 'screenplay',\n",
              " ',',\n",
              " 'cinematography',\n",
              " ',',\n",
              " 'acting',\n",
              " ',',\n",
              " 'post',\n",
              " '-',\n",
              " 'production',\n",
              " ',',\n",
              " 'editing',\n",
              " ',',\n",
              " 'directing',\n",
              " ',',\n",
              " 'or',\n",
              " 'any',\n",
              " 'other',\n",
              " 'aspect',\n",
              " 'of',\n",
              " 'film',\n",
              " '-',\n",
              " 'making',\n",
              " '.',\n",
              " '  ',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'practically',\n",
              " 'perfect',\n",
              " 'in',\n",
              " 'all',\n",
              " 'of',\n",
              " 'them',\n",
              " '\\x96',\n",
              " 'a',\n",
              " 'true',\n",
              " 'masterpiece',\n",
              " 'in',\n",
              " 'a',\n",
              " 'sea',\n",
              " 'of',\n",
              " 'faux',\n",
              " '\"',\n",
              " 'masterpieces',\n",
              " '.',\n",
              " '   ',\n",
              " 'the',\n",
              " 'structure',\n",
              " 'of',\n",
              " 'this',\n",
              " 'film',\n",
              " 'is',\n",
              " 'easily',\n",
              " 'the',\n",
              " 'most',\n",
              " 'tightly',\n",
              " 'constructed',\n",
              " 'in',\n",
              " 'the',\n",
              " 'history',\n",
              " 'of',\n",
              " 'cinema',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'i',\n",
              " 'can',\n",
              " 'think',\n",
              " 'of',\n",
              " 'no',\n",
              " 'other',\n",
              " 'film',\n",
              " 'where',\n",
              " 'something',\n",
              " 'vitally',\n",
              " 'important',\n",
              " 'occurs',\n",
              " 'every',\n",
              " 'other',\n",
              " 'minute',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'in',\n",
              " 'other',\n",
              " 'words',\n",
              " ',',\n",
              " 'the',\n",
              " 'content',\n",
              " 'level',\n",
              " 'of',\n",
              " 'this',\n",
              " 'film',\n",
              " 'is',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'easily',\n",
              " 'fill',\n",
              " 'a',\n",
              " 'dozen',\n",
              " 'other',\n",
              " 'films',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'how',\n",
              " 'can',\n",
              " 'anyone',\n",
              " 'in',\n",
              " 'their',\n",
              " 'right',\n",
              " 'mind',\n",
              " 'ask',\n",
              " 'for',\n",
              " 'anything',\n",
              " 'more',\n",
              " 'from',\n",
              " 'a',\n",
              " 'movie',\n",
              " 'than',\n",
              " 'this',\n",
              " '?',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'quite',\n",
              " 'simply',\n",
              " 'the',\n",
              " 'highest',\n",
              " ',',\n",
              " 'most',\n",
              " 'superlative',\n",
              " 'form',\n",
              " 'of',\n",
              " 'cinema',\n",
              " 'imaginable',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'yes',\n",
              " ',',\n",
              " 'this',\n",
              " 'film',\n",
              " 'does',\n",
              " 'require',\n",
              " 'a',\n",
              " 'rather',\n",
              " 'significant',\n",
              " 'amount',\n",
              " 'of',\n",
              " 'puzzle',\n",
              " '-',\n",
              " 'solving',\n",
              " ',',\n",
              " 'but',\n",
              " 'the',\n",
              " 'pieces',\n",
              " 'fit',\n",
              " 'together',\n",
              " 'to',\n",
              " 'create',\n",
              " 'a',\n",
              " 'beautiful',\n",
              " 'picture',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'this',\n",
              " 'short',\n",
              " 'film',\n",
              " 'certainly',\n",
              " 'pulls',\n",
              " 'no',\n",
              " 'punches',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'graphics',\n",
              " 'is',\n",
              " 'far',\n",
              " 'from',\n",
              " 'the',\n",
              " 'best',\n",
              " 'part',\n",
              " 'of',\n",
              " 'the',\n",
              " 'game',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'number',\n",
              " 'one',\n",
              " 'best',\n",
              " 'th',\n",
              " 'game',\n",
              " 'in',\n",
              " 'the',\n",
              " 'series',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'it',\n",
              " 'deserves',\n",
              " 'strong',\n",
              " 'love',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'it',\n",
              " 'is',\n",
              " 'an',\n",
              " 'insane',\n",
              " 'game',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'there',\n",
              " 'are',\n",
              " 'massive',\n",
              " 'levels',\n",
              " ',',\n",
              " 'massive',\n",
              " 'unlockable',\n",
              " 'characters',\n",
              " '...',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'just',\n",
              " 'a',\n",
              " 'massive',\n",
              " 'game',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'waste',\n",
              " 'your',\n",
              " 'money',\n",
              " 'on',\n",
              " 'this',\n",
              " 'game',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'kind',\n",
              " 'of',\n",
              " 'money',\n",
              " 'that',\n",
              " 'is',\n",
              " 'wasted',\n",
              " 'properly',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'actually',\n",
              " ',',\n",
              " 'the',\n",
              " 'graphics',\n",
              " 'were',\n",
              " 'good',\n",
              " 'at',\n",
              " 'the',\n",
              " 'time',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'today',\n",
              " 'the',\n",
              " 'graphics',\n",
              " 'are',\n",
              " 'crap',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'as',\n",
              " 'they',\n",
              " 'say',\n",
              " 'in',\n",
              " 'canada',\n",
              " ',',\n",
              " 'this',\n",
              " 'is',\n",
              " 'the',\n",
              " 'fun',\n",
              " 'game',\n",
              " ',',\n",
              " 'aye',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'this',\n",
              " 'game',\n",
              " 'rocks',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'buy',\n",
              " 'it',\n",
              " ',',\n",
              " 'play',\n",
              " 'it',\n",
              " ',',\n",
              " 'enjoy',\n",
              " 'it',\n",
              " ',',\n",
              " 'love',\n",
              " 'it',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'pure',\n",
              " 'brilliance',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'this',\n",
              " 'was',\n",
              " 'a',\n",
              " 'flick',\n",
              " 'doomed',\n",
              " 'from',\n",
              " 'its',\n",
              " 'conception',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'the',\n",
              " 'very',\n",
              " 'idea',\n",
              " 'of',\n",
              " 'it',\n",
              " 'was',\n",
              " 'lame',\n",
              " '-',\n",
              " 'take',\n",
              " 'a',\n",
              " 'minor',\n",
              " 'character',\n",
              " 'from',\n",
              " 'a',\n",
              " 'mediocre',\n",
              " 'pg-13',\n",
              " 'film',\n",
              " ',',\n",
              " 'and',\n",
              " 'make',\n",
              " 'a',\n",
              " 'complete',\n",
              " 'non',\n",
              " '-',\n",
              " 'sequel',\n",
              " 'while',\n",
              " 'changing',\n",
              " 'its',\n",
              " 'tone',\n",
              " 'to',\n",
              " 'a',\n",
              " 'pg',\n",
              " '-',\n",
              " 'rated',\n",
              " 'family',\n",
              " 'movie',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'i',\n",
              " 'was',\n",
              " \"n't\",\n",
              " 'the',\n",
              " 'least',\n",
              " 'bit',\n",
              " 'interested',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'not',\n",
              " 'only',\n",
              " 'did',\n",
              " 'it',\n",
              " 'only',\n",
              " 'confirm',\n",
              " 'that',\n",
              " 'the',\n",
              " 'film',\n",
              " 'would',\n",
              " 'be',\n",
              " 'unfunny',\n",
              " 'and',\n",
              " 'generic',\n",
              " ',',\n",
              " 'but',\n",
              " 'it',\n",
              " 'also',\n",
              " 'managed',\n",
              " 'to',\n",
              " 'give',\n",
              " 'away',\n",
              " 'the',\n",
              " 'entire',\n",
              " 'movie',\n",
              " ';',\n",
              " 'and',\n",
              " 'i',\n",
              " \"'m\",\n",
              " 'not',\n",
              " 'exaggerating',\n",
              " '-',\n",
              " 'every',\n",
              " 'moment',\n",
              " ',',\n",
              " 'every',\n",
              " 'plot',\n",
              " 'point',\n",
              " ',',\n",
              " 'every',\n",
              " 'joke',\n",
              " 'is',\n",
              " 'told',\n",
              " 'in',\n",
              " 'the',\n",
              " 'trailer',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'but',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'just',\n",
              " 'not',\n",
              " 'funny',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'but',\n",
              " 'even',\n",
              " 'the',\n",
              " 'talented',\n",
              " 'carrell',\n",
              " 'ca',\n",
              " \"n't\",\n",
              " 'save',\n",
              " 'this',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'his',\n",
              " 'co',\n",
              " '-',\n",
              " 'stars',\n",
              " 'do',\n",
              " \"n't\",\n",
              " 'fare',\n",
              " 'much',\n",
              " 'better',\n",
              " ',',\n",
              " 'with',\n",
              " 'people',\n",
              " 'like',\n",
              " 'morgan',\n",
              " 'freeman',\n",
              " ',',\n",
              " 'jonah',\n",
              " 'hill',\n",
              " ',',\n",
              " 'and',\n",
              " 'ed',\n",
              " 'helms',\n",
              " 'just',\n",
              " 'wasted',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'the',\n",
              " 'story',\n",
              " 'itself',\n",
              " 'is',\n",
              " 'just',\n",
              " 'predictable',\n",
              " 'and',\n",
              " 'lazy',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'the',\n",
              " 'only',\n",
              " 'real',\n",
              " 'effects',\n",
              " 'work',\n",
              " 'is',\n",
              " 'the',\n",
              " 'presence',\n",
              " 'of',\n",
              " 'all',\n",
              " 'the',\n",
              " 'animals',\n",
              " ',',\n",
              " 'and',\n",
              " 'the',\n",
              " 'integration',\n",
              " 'of',\n",
              " 'those',\n",
              " 'into',\n",
              " 'the',\n",
              " 'scenes',\n",
              " 'is',\n",
              " 'some',\n",
              " 'of',\n",
              " 'the',\n",
              " 'worst',\n",
              " 'and',\n",
              " 'most',\n",
              " 'obvious',\n",
              " 'blue',\n",
              " '/',\n",
              " 'green',\n",
              " '-',\n",
              " 'screen',\n",
              " 'work',\n",
              " 'i',\n",
              " \"'ve\",\n",
              " 'ever',\n",
              " 'seen',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'but',\n",
              " 'whatever',\n",
              " 'it',\n",
              " 'was',\n",
              " 'that',\n",
              " 'cost',\n",
              " 'them',\n",
              " 'so',\n",
              " 'much',\n",
              " ',',\n",
              " 'it',\n",
              " 'did',\n",
              " \"n't\",\n",
              " 'translate',\n",
              " 'to',\n",
              " 'quality',\n",
              " ',',\n",
              " 'that',\n",
              " \"'s\",\n",
              " 'for',\n",
              " 'sure',\n",
              " '.',\n",
              " ' \\t',\n",
              " '0',\n",
              " '\\n',\n",
              " 'the',\n",
              " 'film',\n",
              " 'succeeds',\n",
              " 'despite',\n",
              " ',',\n",
              " 'or',\n",
              " 'perhaps',\n",
              " 'because',\n",
              " 'of',\n",
              " ',',\n",
              " 'an',\n",
              " 'obviously',\n",
              " 'meagre',\n",
              " 'budget',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'i',\n",
              " \"'m\",\n",
              " 'glad',\n",
              " 'the',\n",
              " 'film',\n",
              " 'did',\n",
              " \"n't\",\n",
              " 'go',\n",
              " 'for',\n",
              " 'the',\n",
              " 'most',\n",
              " 'obvious',\n",
              " 'choice',\n",
              " ',',\n",
              " 'as',\n",
              " 'a',\n",
              " 'lesser',\n",
              " 'film',\n",
              " 'certainly',\n",
              " 'would',\n",
              " 'have',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'in',\n",
              " 'addition',\n",
              " 'to',\n",
              " 'having',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'most',\n",
              " 'lovely',\n",
              " 'songs',\n",
              " 'ever',\n",
              " 'written',\n",
              " ',',\n",
              " 'french',\n",
              " 'cancan',\n",
              " 'also',\n",
              " 'boasts',\n",
              " 'one',\n",
              " 'of',\n",
              " 'the',\n",
              " 'cutest',\n",
              " 'leading',\n",
              " 'ladies',\n",
              " 'ever',\n",
              " 'to',\n",
              " 'grace',\n",
              " 'the',\n",
              " 'screen',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'hard',\n",
              " 'not',\n",
              " 'to',\n",
              " 'fall',\n",
              " 'head',\n",
              " '-',\n",
              " 'over',\n",
              " '-',\n",
              " 'heels',\n",
              " 'in',\n",
              " 'love',\n",
              " 'with',\n",
              " 'that',\n",
              " 'girl',\n",
              " '.',\n",
              " ' \\t',\n",
              " '1',\n",
              " '\\n',\n",
              " 'on',\n",
              " 'the',\n",
              " 'negative',\n",
              " ',',\n",
              " 'it',\n",
              " \"'s\",\n",
              " 'insipid',\n",
              " 'enough',\n",
              " 'to',\n",
              " 'cause',\n",
              " 'regret',\n",
              " 'for',\n",
              " 'another',\n",
              " '2',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0V8s0bBVsT1"
      },
      "source": [
        "### **What is Stemming?**\n",
        "\n",
        "Stemming is an elementary rule-based process for removing inflectional forms from a token and the outputs are the stem of the world.\n",
        "\n",
        "For example, \"Consult\", \"Consultant\", \"Consulting\", \"Consultantative\" and \"Consultants\" \"Consult\", will all become \"Consult\", which is their stem, because their inflection form will be removed.\n",
        "\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/0*-yUy-dAKeTbPRQuk.png\" height=\"400\" width=\"600\">\n",
        "\n",
        "Stemming is not a good normalization process because sometimes stemming can produce words that are not in the dictionary. For example, consider a sentence: “His teams are not winning”\n",
        "\n",
        "After stemming the tokens that we will get are- “hi”, “team”, “are”, “not”,  “winn”\n",
        "\n",
        "Notice that the keyword “winn” is not a regular word and “hi” changed the context of the entire sentence.\n",
        "\n",
        "- **2 types of stemmers:**\n",
        "  \n",
        "    1. **Porter Stemmer:**\n",
        "    It is one of the most popular stemming methods proposed in 1980. It is based on the idea that the suffixes in the English language are made up of a combination of smaller and simpler suffixes. This stemmer is known for its speed and simplicity. The main applications of Porter Stemmer include data mining and Information retrieval. However, its applications are only limited to English words. Also, the group of stems is mapped on to the same stem and the output stem is not necessarily a meaningful word. The algorithms are fairly lengthy in nature and are known to be the oldest stemmer.\n",
        "        \n",
        "    2. **Snowball stemmer:**\n",
        "    When compared to the Porter Stemmer, the Snowball Stemmer can map non-English words too. Since it supports other languages the Snowball Stemmers can be called a multi-lingual stemmer. The Snowball stemmers are also imported from the nltk package. This stemmer is based on a programming language called ‘Snowball’ that processes small strings and is the most widely used stemmer. The Snowball stemmer is way more aggressive than Porter Stemmer and is also referred to as Porter2 Stemmer. Because of the improvements added when compared to the Porter Stemmer, the Snowball stemmer is having greater computational speed.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4plK3APVsT2",
        "outputId": "05fad1c4-8c25-468d-a423-ce3bd7dc9bed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "#NLTK library used for stemming.\n",
        "from nltk.stem.snowball import PorterStemmer,SnowballStemmer\n",
        "#PorterStemmer\n",
        "port=PorterStemmer()\n",
        "words=[]\n",
        "for word in Text.split(' '):\n",
        "    words.append(port.stem(word))\n",
        "Text_=' '.join(words)\n",
        "Text_"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'becaus of problem with her eyesight, rey the african penguin had issu with swimming. that’ unusu for a penguin,\\nand present a big challeng for our avicultur team to help rey overcom her hesitancy.\\nslowli and steadily, we train her to be comfort feed in the water like the rest of the penguin colony.\\nth aviculturist also train rey to accept daili eye drop from them as part of her special health care.\\nrey alreadi had good relationship with some staff, and wa comfort with them handl her.\\nsenior aviculturist kim fukuda say the team built on those bond to get rey use to receiv the eye drops.\\n\"sh know the routine,\" kim says. \"i usual give her the eye drop in one area of the exhibit after all the penguin get\\ntheir vitamins. when that happens, she run over there and wait for me.\" rosa, our oldest sea otter, ha veri limit eyesight,\\namong other health issues. the sea otter team had alreadi train rosa so they could examin her eyes,\\nand built on that trust to includ administ the eye drop she needs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcqujqbpVsT2",
        "outputId": "c7c8ad43-ab25-489e-deed-79eccbb0dbcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        }
      },
      "source": [
        "#Using SnowballStemmer\n",
        "snow=SnowballStemmer('english')\n",
        "words=[]\n",
        "for word in Text.split(' '):\n",
        "    words.append(snow.stem(word))\n",
        "Text_=' '.join(words)\n",
        "Text_"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'becaus of problem with her eyesight, rey the african penguin had issu with swimming. that unusu for a penguin,\\nand present a big challeng for our avicultur team to help rey overcom her hesitancy.\\nslowli and steadily, we train her to be comfort feed in the water like the rest of the penguin colony.\\nth aviculturist also train rey to accept daili eye drop from them as part of her special health care.\\nrey alreadi had good relationship with some staff, and was comfort with them handl her.\\nsenior aviculturist kim fukuda say the team built on those bond to get rey use to receiv the eye drops.\\n\"sh know the routine,\" kim says. \"i usual give her the eye drop in one area of the exhibit after all the penguin get\\ntheir vitamins. when that happens, she run over there and wait for me.\" rosa, our oldest sea otter, has veri limit eyesight,\\namong other health issues. the sea otter team had alreadi train rosa so they could examin her eyes,\\nand built on that trust to includ administ the eye drop she needs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZdBhW-wVsT3"
      },
      "source": [
        "#stemming the review from imdb dataset.\n",
        "imdb['clean']=imdb['clean'].apply(lambda x: \" \".join([snow.stem(word) for word in x.split()]))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg8ObbF8VsT3",
        "outputId": "4f74dedf-0093-4b2a-c93d-6d2ed353d13c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "imdb['clean']"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        slow move aimless movi distress drift young man\n",
              "1          sure lost flat charact audienc near half walk\n",
              "2      attempt arti black white clever camera angl mo...\n",
              "3                                littl music anyth speak\n",
              "4      best scene movi gerardo tri find song keep run...\n",
              "                             ...                        \n",
              "743                got bore watch jessic lang take cloth\n",
              "744    unfortun virtu film product work lost regrett ...\n",
              "745                                       word embarrass\n",
              "746                                           except bad\n",
              "747                  insult one intellig huge wast money\n",
              "Name: clean, Length: 748, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtDMu8cpVsT4"
      },
      "source": [
        "### **What is Lemmatization?**\n",
        "Lemmatization, on the other hand, is a systematic step-by-step process for removing inflection forms of a word. It makes use of vocabulary, word structure, part of speech tags, and grammar relations.\n",
        "\n",
        "The output of lemmatization is the root word called a lemma. For example,\n",
        "\n",
        "Am, Are, Is >> Be\n",
        "\n",
        "Running, Ran, Run >> Run\n",
        "\n",
        "Also, since it is a systematic process while performing lemmatization one can specify the part of the speech tag for the desired term and lemmatization will only be performed if the given word has the proper part of the speech tag. For example, if we try to lemmatize the word running as a verb, it will be converted to run. But if we try to lemmatize the same word running as a noun it won’t be converted.\n",
        "\n",
        "![title](https://cdn.analyticsvidhya.com/wp-content/uploads/2021/02/Screenshot-from-2021-02-23-15-07-22.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoFbS6XBVsT5",
        "outputId": "cc4e8833-5339-47a1-b9df-d89c44df08a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "nltk.download('wordnet')\n",
        "from nltk import WordNetLemmatizer\n",
        "lemma=WordNetLemmatizer()\n",
        "words=[]\n",
        "for word in Text.split(' '):\n",
        "    words.append(lemma.lemmatize(word))\n",
        "Text_=' '.join(words)\n",
        "Text_"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Because of problem with her eyesight, rey the African penguin had issue with swimming. That’s unusual for a penguin,\\nand presented a big challenge for our aviculture team to help Rey overcome her hesitancy.\\nSlowly and steadily, we trained her to be comfortable feeding in the water like the rest of the penguin colony.\\nThe aviculturists also trained Rey to accept daily eye drop from them a part of her special health care.\\nRey already had good relationship with some staff, and wa comfortable with them handling her.\\nSenior Aviculturist Kim Fukuda say the team built on those bond to get Rey used to receiving the eye drops.\\n\"She know the routine,\" Kim says. \"I usually give her the eye drop in one area of the exhibit after all the penguin get\\ntheir vitamins. When that happens, she run over there and wait for me.\" Rosa, our oldest sea otter, ha very limited eyesight,\\namong other health issues. The sea otter team had already trained Rosa so they could examine her eyes,\\nand built on that trust to include administering the eye drop she needs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa4N7_xcVsT5"
      },
      "source": [
        "### **Parts of Speech Tagging**\n",
        "\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:828/format:webp/1*6Ps5SSxIwH28b_RLYQ2Sqw.jpeg\" height=\"400\" width=\"500\">\n",
        "\n",
        "For any language, syntax and structure usually go hand in hand, where a set of specific rules, conventions, and principles govern the way words are combined into phrases; phrases get combines into clauses; and clauses get combined into sentences.\n",
        "\n",
        "Knowledge about the structure and syntax of language is helpful in many areas like text processing, annotation, and parsing for further operations such as text classification or summarization.\n",
        "\n",
        "__Parts of speech (POS)__ are specific lexical categories to which words are assigned, based on their syntactic context and role. Usually, words can fall into one of the following major categories.\n",
        "\n",
        "+ __N(oun)__: This usually denotes words that depict some object or entity, which may be living or nonliving. Some examples would be fox , dog , book , and so on. The POS tag symbol for nouns is N.\n",
        "\n",
        "+ __V(erb)__: Verbs are words that are used to describe certain actions, states, or occurrences. There are a wide variety of further subcategories, such as auxiliary, reflexive, and transitive verbs (and many more). Some typical examples of verbs would be running , jumping , read , and write . The POS tag symbol for verbs is V.\n",
        "\n",
        "+ __Adj(ective)__: Adjectives are words used to describe or qualify other words, typically nouns and noun phrases. The phrase beautiful flower has the noun (N) flower which is described or qualified using the adjective (ADJ) beautiful . The POS tag symbol for adjectives is ADJ .\n",
        "\n",
        "+ __Adv(erb)__: Adverbs usually act as modifiers for other words including nouns, adjectives, verbs, or other adverbs. The phrase very beautiful flower has the adverb (ADV) very , which modifies the adjective (ADJ) beautiful , indicating the degree to which the flower is beautiful. The POS tag symbol for adverbs is ADV.\n",
        "\n",
        "Besides these four major categories of parts of speech , there are other categories that occur frequently in the English language. These include pronouns, prepositions, interjections, conjunctions, determiners, and many others. Furthermore, each POS tag like the noun (N) can be further subdivided into categories like __singular nouns (NN)__, __singular proper nouns (NNP)__, and __plural nouns (NNS)__.\n",
        "\n",
        "The process of classifying and labeling POS tags for words called parts of speech tagging or POS tagging ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR43nt7XVsT6"
      },
      "source": [
        "### **Guide to POS Tags**\n",
        "\n",
        "The most common part of speech (POS) tag schemes are those developed for the Penn Treebank.\n",
        "\n",
        "| POS Tag | Description | Example |\n",
        "|---------|---------------------------------------|-----------------------------------------|\n",
        "| CC | coordinating conjunction | and |\n",
        "| CD | cardinal number | 1, third |\n",
        "| DT | determiner | the |\n",
        "| EX | existential there | there is |\n",
        "| FW | foreign word | d’hoevre |\n",
        "| IN | preposition/subordinating conjunction | in, of, like |\n",
        "| JJ | adjective | big |\n",
        "| JJR | adjective, comparative | bigger |\n",
        "| JJS | adjective, superlative | biggest |\n",
        "| LS | list marker | 1) |\n",
        "| MD | modal | could, will |\n",
        "| NN | noun, singular or mass | door |\n",
        "| NNS | noun plural | doors |\n",
        "| NNP | proper noun, singular | John |\n",
        "| NNPS | proper noun, plural | Vikings |\n",
        "| PDT | predeterminer | both the boys |\n",
        "| POS | possessive ending | friend‘s |\n",
        "| PRP | personal pronoun | I, he, it |\n",
        "| PRP\\$ | possessive pronoun | my, his |\n",
        "| RB | adverb | however, usually, naturally, here, good |\n",
        "| RBR | adverb, comparative | better |\n",
        "| RBS | adverb, superlative | best |\n",
        "| RP | particle | give up |\n",
        "| TO | to | to go, to him |\n",
        "| UH | interjection | uhhuhhuhh |\n",
        "| VB | verb, base form | take |\n",
        "| VBD | verb, past tense | took |\n",
        "| VBG | verb, gerund/present participle | taking |\n",
        "| VBN | verb, past participle | taken |\n",
        "| VBP | verb, sing. present, non-3d | take |\n",
        "| VBZ | verb, 3rd person sing. present | takes |\n",
        "| WDT | wh-determiner | which |\n",
        "| WP | wh-pronoun | who, what |\n",
        "| WP\\$ | possessive wh-pronoun | whose |\n",
        "| WRB | wh-abverb | where, when |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jb2L9gGNVsT7"
      },
      "source": [
        "### **POS Using NLTK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14la_tn2VsT8",
        "outputId": "97522ab8-e48a-409f-e3ab-035766d6695d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "source": [
        "sentence = 'Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin'\n",
        "sentence"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoIffbcfVsT8",
        "outputId": "d25d2b9b-4f31-4b28-880b-4a3ff74781e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcv-EJFJVsT9",
        "outputId": "a0aa36f3-a748-4421-eeea-e3ef134d28ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Tokenize each word using word_tokenize using nltk module thne find the pos tag for each word.\n",
        "nltk_pos_tagged = nltk.pos_tag(word_tokenize(sentence))\n",
        "nltk_pos_tagged"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mr.', 'NNP'),\n",
              " ('Trump', 'NNP'),\n",
              " ('became', 'VBD'),\n",
              " ('president', 'NN'),\n",
              " ('after', 'IN'),\n",
              " ('winning', 'VBG'),\n",
              " ('the', 'DT'),\n",
              " ('political', 'JJ'),\n",
              " ('election', 'NN'),\n",
              " ('.', '.'),\n",
              " ('Though', 'IN'),\n",
              " ('he', 'PRP'),\n",
              " ('lost', 'VBD'),\n",
              " ('the', 'DT'),\n",
              " ('support', 'NN'),\n",
              " ('of', 'IN'),\n",
              " ('some', 'DT'),\n",
              " ('republican', 'JJ'),\n",
              " ('friends', 'NNS'),\n",
              " (',', ','),\n",
              " ('Trump', 'NNP'),\n",
              " ('is', 'VBZ'),\n",
              " ('friends', 'NNS'),\n",
              " ('with', 'IN'),\n",
              " ('President', 'NNP'),\n",
              " ('Putin', 'NNP')]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNj7a4tvVsT-",
        "outputId": "906dd323-9f07-408e-e121-b79b92b3ff14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 864
        }
      },
      "source": [
        "#creating dataframe for word and its tag.\n",
        "POS_df=pd.DataFrame(nltk_pos_tagged,\n",
        "             columns=['Word', 'POS tag'])\n",
        "POS_df"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Word POS tag\n",
              "0          Mr.     NNP\n",
              "1        Trump     NNP\n",
              "2       became     VBD\n",
              "3    president      NN\n",
              "4        after      IN\n",
              "5      winning     VBG\n",
              "6          the      DT\n",
              "7    political      JJ\n",
              "8     election      NN\n",
              "9            .       .\n",
              "10      Though      IN\n",
              "11          he     PRP\n",
              "12        lost     VBD\n",
              "13         the      DT\n",
              "14     support      NN\n",
              "15          of      IN\n",
              "16        some      DT\n",
              "17  republican      JJ\n",
              "18     friends     NNS\n",
              "19           ,       ,\n",
              "20       Trump     NNP\n",
              "21          is     VBZ\n",
              "22     friends     NNS\n",
              "23        with      IN\n",
              "24   President     NNP\n",
              "25       Putin     NNP"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dfde2ec3-cb30-4292-9117-f6c83d8a6b4e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>POS tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mr.</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>became</td>\n",
              "      <td>VBD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>president</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>after</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>winning</td>\n",
              "      <td>VBG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>political</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>election</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Though</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>he</td>\n",
              "      <td>PRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>lost</td>\n",
              "      <td>VBD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>support</td>\n",
              "      <td>NN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>of</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>some</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>republican</td>\n",
              "      <td>JJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>friends</td>\n",
              "      <td>NNS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>,</td>\n",
              "      <td>,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Trump</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>is</td>\n",
              "      <td>VBZ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>friends</td>\n",
              "      <td>NNS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>with</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>President</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Putin</td>\n",
              "      <td>NNP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dfde2ec3-cb30-4292-9117-f6c83d8a6b4e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dfde2ec3-cb30-4292-9117-f6c83d8a6b4e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dfde2ec3-cb30-4292-9117-f6c83d8a6b4e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9e7228fb-4659-4c62-bdca-e87f4a5aceaa\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9e7228fb-4659-4c62-bdca-e87f4a5aceaa')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9e7228fb-4659-4c62-bdca-e87f4a5aceaa button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_92ee1dd3-65ee-4195-9fc2-85b641595f91\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('POS_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_92ee1dd3-65ee-4195-9fc2-85b641595f91 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('POS_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "POS_df",
              "summary": "{\n  \"name\": \"POS_df\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"some\",\n          \".\",\n          \"Mr.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \",\",\n          \"NNS\",\n          \"NNP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZyN8dwYVsT-"
      },
      "source": [
        "### **POS Using Spacy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqq09N1uVsT_",
        "outputId": "f514e376-3418-48d3-fe49-667f5856e633",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import spacy #loading spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm') # english module.\n",
        "\n",
        "sentence_nlp = nlp(sentence)\n",
        "spacy_pos_tagged = [(word, word.tag_, word.pos_) for word in sentence_nlp]\n",
        "spacy_pos_tagged"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(Mr., 'NNP', 'PROPN'),\n",
              " (Trump, 'NNP', 'PROPN'),\n",
              " (became, 'VBD', 'VERB'),\n",
              " (president, 'NN', 'NOUN'),\n",
              " (after, 'IN', 'ADP'),\n",
              " (winning, 'VBG', 'VERB'),\n",
              " (the, 'DT', 'DET'),\n",
              " (political, 'JJ', 'ADJ'),\n",
              " (election, 'NN', 'NOUN'),\n",
              " (., '.', 'PUNCT'),\n",
              " (Though, 'IN', 'SCONJ'),\n",
              " (he, 'PRP', 'PRON'),\n",
              " (lost, 'VBD', 'VERB'),\n",
              " (the, 'DT', 'DET'),\n",
              " (support, 'NN', 'NOUN'),\n",
              " (of, 'IN', 'ADP'),\n",
              " (some, 'DT', 'DET'),\n",
              " (republican, 'JJ', 'ADJ'),\n",
              " (friends, 'NNS', 'NOUN'),\n",
              " (,, ',', 'PUNCT'),\n",
              " (Trump, 'NNP', 'PROPN'),\n",
              " (is, 'VBZ', 'AUX'),\n",
              " (friends, 'NNS', 'NOUN'),\n",
              " (with, 'IN', 'ADP'),\n",
              " (President, 'NNP', 'PROPN'),\n",
              " (Putin, 'NNP', 'PROPN')]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akcy9urfVsT_",
        "outputId": "770b262f-cccc-4709-a2c3-4c815e96570c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "spacy_POS_DF=pd.DataFrame(spacy_pos_tagged, columns=['Word', 'POS Tag', 'Tag Type'])\n",
        "spacy_POS_DF.head(10)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        Word POS Tag Tag Type\n",
              "0        Mr.     NNP    PROPN\n",
              "1      Trump     NNP    PROPN\n",
              "2     became     VBD     VERB\n",
              "3  president      NN     NOUN\n",
              "4      after      IN      ADP\n",
              "5    winning     VBG     VERB\n",
              "6        the      DT      DET\n",
              "7  political      JJ      ADJ\n",
              "8   election      NN     NOUN\n",
              "9          .       .    PUNCT"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32acbfc5-23b7-4284-9dc2-c64b32c79d6e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>POS Tag</th>\n",
              "      <th>Tag Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mr.</td>\n",
              "      <td>NNP</td>\n",
              "      <td>PROPN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Trump</td>\n",
              "      <td>NNP</td>\n",
              "      <td>PROPN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>became</td>\n",
              "      <td>VBD</td>\n",
              "      <td>VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>president</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>after</td>\n",
              "      <td>IN</td>\n",
              "      <td>ADP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>winning</td>\n",
              "      <td>VBG</td>\n",
              "      <td>VERB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>the</td>\n",
              "      <td>DT</td>\n",
              "      <td>DET</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>political</td>\n",
              "      <td>JJ</td>\n",
              "      <td>ADJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>election</td>\n",
              "      <td>NN</td>\n",
              "      <td>NOUN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>.</td>\n",
              "      <td>.</td>\n",
              "      <td>PUNCT</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32acbfc5-23b7-4284-9dc2-c64b32c79d6e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32acbfc5-23b7-4284-9dc2-c64b32c79d6e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32acbfc5-23b7-4284-9dc2-c64b32c79d6e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-97cfc12e-00c7-4e7b-af32-27fa9394f794\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-97cfc12e-00c7-4e7b-af32-27fa9394f794')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-97cfc12e-00c7-4e7b-af32-27fa9394f794 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "spacy_POS_DF",
              "summary": "{\n  \"name\": \"spacy_POS_DF\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"election\",\n          \"some\",\n          \"Mr.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"POS Tag\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \",\",\n          \"NNS\",\n          \"NNP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Tag Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"PRON\",\n          \"VERB\",\n          \"ADJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XzdehWVVsUW"
      },
      "source": [
        "**End of Notebook**"
      ]
    }
  ]
}